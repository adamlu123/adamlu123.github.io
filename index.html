<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Yadong (Adam) Lu</title> <meta name="author" content="Yadong (Adam) Lu"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://adamlu123.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <div class="toggle-container"> <a id="light-toggle"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </a> </div> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Yadong (Adam)</span> Lu </h1> <p class="desc">Senior Researcher / enthusiastic go player </p> </header> <article> <div class="profile float-right"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/prof_pic.jpg" alt="prof_pic.jpg"> </picture> </figure> </div> <div class="clearfix"> <p>I am a senior researcher at Microsoft Research, Redmond working on efficient pre/post-training methodologies of large vision-language models. Before that I received my Ph.D. degree in Statistics at UC Irvine (advisor: <a href="https://scholar.google.com/citations?user=RhFhIIgAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Pierre Baldi</a>).</p> <p>Check out our recent work on computer use agent <a href="https://github.com/microsoft/OmniParser" target="_blank" rel="noopener noreferrer">OmniParser</a> (ranked #1 Trending repo on GitHub and HuggingFace model hub, 22k+ star so far), and <a href="https://arxiv.org/abs/2502.11357" target="_blank" rel="noopener noreferrer">scaling synthetic trajectory data for web agent</a>.</p> </div> <div class="publications"> <h2>Selected Works</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Arxiv</abbr></div> <div id="lu2024omniparserpurevisionbased" class="col-sm-8"> <div class="title">OmniParser for Pure Vision Based GUI Agent</div> <div class="author">Lu, Yadong, Yang, Jianwei, Shen, Yelong, and Awadallah, Ahmed </div> <div class="periodical"> 2024 </div> <div class="links"> <a href="https://arxiv.org/abs/2408.00203" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CVPR</abbr></div> <div id="bonatti2024windowsagentarenaevaluating" class="col-sm-8"> <div class="title">Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale</div> <div class="author">Bonatti, Rogerio, Zhao, Dan, Bonacci, Francesco, Dupont, Dillon, Abdali, Sara, Li, Yinheng, Lu, Yadong, Wagle, Justin, Koishida, Kazuhito, Bucker, Arthur, Jang, Lawrence, and Hui, Zack </div> <div class="periodical"> <em>CVPR</em> 2025 </div> <div class="links"> <a href="https://arxiv.org/abs/2409.08264" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div> <div id="ren2024sambasimplehybridstate" class="col-sm-8"> <div class="title">Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling</div> <div class="author">Ren, Liliang, Liu, Yang, Lu, Yadong, Shen, Yelong, Liang, Chen, and Chen, Weizhu </div> <div class="periodical"> <em>ICLR</em> 2024 </div> <div class="links"> <a href="https://arxiv.org/abs/2406.07522" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">TMLR</abbr></div> <div id="zhong2024multiloracompositionimagegeneration" class="col-sm-8"> <div class="title">Multi-LoRA Composition for Image Generation</div> <div class="author">Zhong, Ming, Shen, Yelong, Wang, Shuohang, Lu, Yadong, Jiao, Yizhu, Ouyang, Siru, Yu, Donghan, Han, Jiawei, and Chen, Weizhu </div> <div class="periodical"> <em>TMLR</em> 2024 </div> <div class="links"> <a href="https://arxiv.org/abs/2402.16843" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Arxiv</abbr></div> <div id="scaling_VL" class="col-sm-8"> <div class="title">An Empirical Study of Scaling Instruction-Tuned Large Multimodal Models</div> <div class="author">Yadong, Lu, Chunyuan, Li, Haotian, Liu, Jianwei, Yang, Jianfeng, Gao, and Yelong, Shen </div> <div class="periodical"> <em>NeurIPS, Workshop on Instruction Tuning and Instruction Following</em> NeurIPS </div> <div class="links"> <a href="https://arxiv.org/pdf/2309.09958.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Arxiv</abbr></div> <div id="hydra_rlhf" class="col-sm-8"> <div class="title">Efficient RLHF: Reducing the Memory Usage of PPO</div> <div class="author">Michael, Santacroce, Yadong, Lu, Han, Yu, Yuanzhi, Li, and Yelong, Shen </div> <div class="periodical"> <em>Arxiv</em> 2023 </div> <div class="links"> <a href="https://arxiv.org/pdf/2309.00754.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="in_context" class="col-sm-8"> <div class="title">In-Context Learning Unlocked for Diffusion Models</div> <div class="author">Wang, Zhendong, Jiang, Yifan, Lu, Yadong, Shen, Yelong, He, Pengcheng, Chen, Weizhu, Wang, Zhangyang, and Zhou, Mingyuan </div> <div class="periodical"> <em>NeurIPS Spotlight</em> 2023 </div> <div class="links"> <a href="https://arxiv.org/abs/2305.01115" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Patent</abbr></div> <div id="https://doi.org/10.48550/arxiv.2202.00723" class="col-sm-8"> <div class="title">Progressive data compression using artificial neural networks</div> <div class="author">Lu, Yadong, Yang, Yang, Zhu, Yinhao, Said, Amir, and Cohen, Taco </div> <div class="periodical"> <em>US Patent</em> 2022 </div> <div class="links"> <a href="https://patents.google.com/patent/US20220237740A1/en" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Patent</abbr></div> <div id="https://doi.org/10.48550/arxiv.2202.00724" class="col-sm-8"> <div class="title">Variable bit rate compression using neural network models</div> <div class="author">Lu, Yadong, Yang, Yang, Zhu, Yinhao, Said, Amir, Pourreza, Reza, and Cohen, Taco </div> <div class="periodical"> <em>US Patent</em> 2022 </div> <div class="links"> <a href="https://patents.google.com/patent/US20220224926A1/en" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">JHEP</abbr></div> <div id="https://doi.org/10.48550/arxiv.2202.00725" class="col-sm-8"> <div class="title">Resolving Extreme Jet Substructure</div> <div class="author">Lu, Yadong, Romero, Alexis, Fenton, Michael James, Whiteson, Daniel, and Baldi, Pierre </div> <div class="periodical"> <em>Journal of High Energy Physics</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/article/10.1007/JHEP08(2022)046" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>We study the effectiveness of theoretically-motivated high-level jet observables in the extreme context of jets with a large number of hard sub-jets (up to N=8). Previous studies indicate that high-level observables are powerful, interpretable tools to probe jet substructure for N≤3 hard sub-jets, but that deep neural networks trained on low-level jet constituents match or slightly exceed their performance. We extend this work for up to N=8 hard sub-jets, using deep particle-flow networks (PFNs) and Transformer based networks to estimate a loose upper bound on the classification performance. The high-level jet observables perform well, with an overall classification accuracy of 86.90%, but fall short of the PFN and Transformer models, which reach classification accuracies of 89.19% and 91.27% respectively, suggesting that the constituent networks utilize information not captured by the set of high-level observables. We then identify additional high-level observables which are able to narrow this gap, and utilize LASSO regularization for feature selection to identify and rank the most relevant observables and provide further insights into the learning strategies used by the constituent-based neural networks. The final model contains only 31 high-level observables and is able to match the performance of the PFN and approximate the performance of the Transformer model to within 2%.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ECCV</abbr></div> <div id="Wang2020DifferentiableJP" class="col-sm-8"> <div class="title">Differentiable Joint Pruning and Quantization for Hardware Efficiency</div> <div class="author">Wang, Yin, Lu, Yadong, and Blankevoort, Tijmen </div> <div class="periodical"> <em>European Conference on Computer Vision (ECCV)</em> 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2007.10463" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>We present a differentiable joint pruning and quantization (DJPQ) scheme. We frame neural network compression as a joint gradient-based optimization problem, trading off between model pruning and quantization automatically for hardware efficiency. DJPQ incorporates variational information bottleneck based structured pruning and mixed-bit precision quantization into a single differentiable loss function. In contrast to previous works which consider pruning and quantization separately, our method enables users to find the optimal trade-off between both in a single training procedure. To utilize the method for more efficient hardware inference, we extend DJPQ to integrate structured pruning with power-of-two bit-restricted quantization. We show that DJPQ significantly reduces the number of Bit-Operations (BOPs) for several networks while maintaining the top-1 accuracy of original floating-point models (e.g., 53x BOPs reduction in ResNet18 on ImageNet, 43x in MobileNetV2). Compared to the conventional two-stage approach, which optimizes pruning and quantization independently, our scheme outperforms in terms of both accuracy and BOPs. Even when considering bit-restricted quantization, DJPQ achieves larger compression ratios and better accuracy than the two-stage approach.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICIP</abbr></div> <div id="plonq" class="col-sm-8"> <div class="title">Progressive Neural Image Compression With Nested Quantization And Latent Ordering</div> <div class="author">Lu, Yadong*, Zhu, Yinhao*, Yang, Yang*, Said, Amir, and Cohen, Taco S </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/9506026" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>We present PLONQ, a progressive neural image compression scheme which pushes the boundary of variable bitrate compression by allowing quality scalable coding with a single bitstream. In contrast to existing learned variable bitrate solutions which produce separate bitstreams for each quality, it enables easier rate-control and requires less storage. Leveraging the latent scaling based variable bitrate solution, we introduce nested quantization, a method that defines multiple quantization levels with nested quantization grids, and progressively refines all latents from the coarsest to the finest quantization level. To achieve finer progressiveness in between any two quantization levels, latent elements are incrementally refined with an importance ordering defined in the rate-distortion sense. To the best of our knowledge, PLONQ is the first learning-based progressive image coding scheme and it outperforms SPIHT, a well-known wavelet-based progressive image codec.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%61%64%61%6D%6C%75%31%31%32%38@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=Y69ahdAAAAAJ&amp;hl" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/adamlu123" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/yadong-adam-lu-90a35b87" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://adamlu123.github.io/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> You can even add a little note about which of these is the best way to reach you. </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Yadong (Adam) Lu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script src="/assets/js/zoom.js"></script> <script src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>